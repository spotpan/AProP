import torch
#from hitsgnn import HITSGNN
from hitsgnn_rev2 import HITSGNN
from utils import *
import argparse
import numpy as np
from metattack import MetaApprox, Metattack
import torch.nn.functional as F
import torch.optim as optim
import seaborn as sns
from matplotlib import pyplot as plt
import pandas as pd

parser = argparse.ArgumentParser()
parser.add_argument('--seed', type=int, default=18, help='Random seed.')
parser.add_argument('--epochs', type=int, default=200,
                    help='Number of epochs to train.')
parser.add_argument('--lr', type=float, default=0.01,
                    help='Initial learning rate.')
parser.add_argument('--hidden', type=int, default=16,
                    help='Number of hidden units.')
parser.add_argument('--dataset', type=str, default='citeseer',
                    choices=['cora', 'cora_ml', 'citeseer', 'polblogs'], help='dataset')
parser.add_argument('--ptb_rate', type=float, default=0.05,  help='pertubation rate')
parser.add_argument('--model', type=str, default='Meta-Self', choices=['A-Meta-Self', 'Meta-Self'], help='model variant')

args = parser.parse_args()
cuda = torch.cuda.is_available()
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

np.random.seed(args.seed)
torch.manual_seed(args.seed)
if device != 'cpu':
    torch.cuda.manual_seed(args.seed)

# === loading dataset
adj, features, labels = load_data(dataset=args.dataset)
nclass = max(labels) + 1

val_size = 0.1
test_size = 0.8
train_size = 1 - test_size - val_size

idx = np.arange(adj.shape[0])
idx_train, idx_val, idx_test = get_train_val_test(idx, train_size, val_size, test_size, stratify=labels)


print("idx_test", type(idx_test))



idx_test1=[2, 514, 1540, 517, 2054, 519, 1539, 522, 524, 1037, 1038, 527, 528, 2063, 2065, 531, 2067, 1046, 1569, 2082, 1574, 2088, 2094, 558, 1074, 564, 567, 1609, 1610, 588, 590, 1110, 95, 1632, 1634, 1130, 1137, 628, 117, 1145, 1146, 633, 1668, 650, 144, 151, 155, 158, 1184, 165, 683, 1194, 176, 1716, 181, 1717, 702, 1727, 1733, 1221, 199, 1736, 1226, 723, 1748, 725, 729, 1242, 1243, 731, 1246, 735, 1760, 1761, 737, 1754, 1252, 231, 1768, 743, 236, 241, 1266, 1267, 242, 1781, 249, 754, 251, 1276, 1788, 774, 1801, 266, 1806, 274, 1299, 277, 1818, 797, 1824, 1826, 292, 1319, 1832, 1831, 804, 1833, 814, 305, 307, 309, 1339, 1852, 828, 1862, 1351, 841, 332, 1363, 1875, 1876, 1370, 350, 1891, 355, 873, 877, 880, 369, 1397, 376, 889, 378, 380, 1917, 898, 902, 1928, 1930, 1931, 907, 1421, 1425, 913, 1429, 1430, 919, 407, 410, 414, 1446, 1960, 937, 1452, 1965, 1966, 1972, 951, 441, 442, 1979, 444, 1469, 1468, 445, 1985, 450, 1986, 1988, 1989, 454, 455, 1992, 1480, 458, 970, 1487, 464, 1999, 981, 2006, 2007, 1495, 2011, 989, 2018, 1506, 995, 997, 1505, 1000, 1515, 1516, 493, 1007, 496, 1523, 2037, 1528, 1017, 1018, 2044]

idx_test2=[1, 2051, 2052, 4, 2055, 2054, 2062, 6, 12, 19, 2068, 21, 2070, 24, 5, 2075, 28, 2077, 30, 32, 34, 36, 39, 2084, 2090, 38, 2093, 2091, 50, 51, 2099, 54, 66, 71, 75, 78, 80, 83, 85, 89, 90, 2053, 91, 97, 98, 100, 102, 105, 118, 138, 144, 157, 162, 166, 171, 173, 183, 201, 204, 2076, 211, 2079, 225, 226, 228, 230, 239, 246, 253, 257, 265, 266, 278, 310, 317, 318, 322, 332, 362, 380, 382, 415, 427, 430, 436, 437, 447, 451, 452, 473, 498, 516, 524, 537, 583, 598, 601, 602, 612, 614, 622, 623, 624, 628, 630, 631, 636, 638, 640, 644, 652, 654, 655, 657, 658, 662, 664, 666, 667, 668, 678, 680, 684, 685, 688, 700, 708, 710, 716, 718, 724, 728, 736, 737, 742, 746, 754, 759, 763, 764, 766, 782, 784, 787, 792, 794, 803, 804, 815, 817, 830, 831, 833, 848, 850, 862, 867, 869, 870, 873, 875, 878, 879, 885, 886, 897, 898, 904, 905, 906, 917, 922, 927, 935, 936, 938, 941, 945, 949, 950, 953, 962, 968, 974, 982, 983, 987, 988, 989, 992, 999, 1001, 1002, 1007, 1012, 1013, 1018, 1021, 1033, 1035, 1038, 1041, 1042, 1048, 1049, 1058, 1063, 1069, 1070, 1072, 1075, 1079, 1084, 1091, 1092, 1104, 1109, 1110, 1122, 1130, 1140, 1144, 1149, 1151, 1152, 1160, 1171, 1178, 1180, 1191, 1193, 1194, 1196, 1206, 1216, 1220, 1225, 1231, 1243, 1251, 1261, 1263, 1271, 1273, 1276, 1277, 1285, 1298, 1299, 1302, 1311, 1322, 1324, 1333, 1339, 1348, 1354, 1355, 1366, 1368, 1376, 1381, 1387, 1390, 1391, 1392, 1396, 1397, 1400, 1417, 1418, 1419, 1428, 1433, 1434, 1437, 1439, 1453, 1454, 1455, 1458, 1467, 1468, 1471, 1476, 1481, 1485, 1487, 1491, 1492, 1496, 1503, 1531, 1543, 1547, 1551, 1553, 1554, 1562, 1572, 1574, 1584, 1587, 1594, 1603, 1611, 1612, 1615, 1618, 1620, 1623, 1633, 1637, 1648, 1652, 1656, 1665, 1671, 1677, 1690, 1691, 1694, 1696, 1706, 1707, 1716, 1725, 1733, 1749, 1752, 1766, 1786, 1787, 1793, 1795, 1801, 1804, 1805, 1818, 1829, 1833, 1838, 1839, 1842, 1843, 1847, 1848, 1856, 1859, 1868, 1876, 1884, 1894, 1904, 1908, 1917, 1933, 1940, 1951, 1963, 1980, 1982, 1986, 1987, 1988, 1999, 2023, 2039]

idx_test3=[2051, 5, 2055, 2060, 2062, 16, 2065, 2067, 17, 2069, 2068, 2072, 25, 20, 2075, 28, 2073, 2078, 2079, 34, 2084, 2082, 40, 2089, 44, 2093, 2095, 2096, 49, 2098, 53, 55, 2104, 2105, 57, 2107, 2108, 59, 63, 2109, 71, 72, 78, 80, 82, 83, 84, 85, 87, 88, 91, 95, 98, 102, 103, 104, 106, 111, 112, 113, 119, 120, 133, 143, 144, 145, 146, 151, 155, 157, 158, 161, 162, 165, 168, 169, 173, 175, 176, 178, 179, 180, 181, 187, 188, 196, 202, 204, 209, 210, 212, 213, 214, 215, 225, 228, 232, 233, 236, 241, 242, 247, 250, 253, 256, 261, 266, 271, 272, 274, 278, 279, 285, 290, 301, 302, 307, 314, 316, 323, 329, 340, 343, 344, 345, 346, 347, 349, 352, 356, 362, 366, 367, 369, 370, 375, 376, 378, 379, 380, 381, 382, 384, 385, 389, 393, 394, 398, 400, 404, 407, 408, 410, 416, 417, 419, 423, 424, 430, 431, 435, 441, 442, 444, 445, 446, 447, 449, 450, 456, 457, 459, 461, 462, 464, 471, 472, 474, 476, 482, 484, 486, 487, 489, 491, 497, 500, 502, 503, 504, 506, 507, 513, 515, 517, 518, 519, 523, 524, 525, 530, 531, 532, 535, 536, 540, 542, 543, 544, 545, 547, 551, 553, 559, 568, 571, 572, 574, 575, 578, 581, 590, 592, 593, 595, 597, 598, 606, 613, 614, 622, 625, 627, 628, 631, 634, 638, 639, 640, 642, 649, 650, 652, 660, 661, 664, 667, 668, 683, 684, 685, 690, 691, 692, 702, 704, 710, 712, 717, 718, 719, 723, 735, 736, 737, 738, 742, 746, 754, 755, 759, 764, 778, 785, 786, 791, 794, 804, 806, 810, 813, 816, 817, 818, 819, 820, 821, 828, 833, 844, 850, 851, 852, 858, 861, 862, 863, 866, 873, 875, 878, 879, 880, 884, 889, 890, 893, 895, 897, 898, 902, 904, 907, 912, 918, 920, 928, 933, 934, 935, 937, 948, 949, 950, 958, 959, 961, 962, 964, 966, 967, 970, 974, 975, 976, 980, 986, 987, 989, 998, 999, 1000, 1002, 1006, 1017, 1018, 1021, 1022, 1023, 1026, 1028, 1031, 1035, 1036, 1038, 1045, 1046, 1048, 1049, 1052, 1057, 1058, 1060, 1063, 1066, 1068, 1069, 1071, 1074, 1075, 1077, 1081, 1084, 1085, 1089, 1092, 1096, 1097, 1100, 1103, 1108, 1110, 1112, 1118, 1121, 1127, 1132, 1136, 1137, 1145, 1146, 1153, 1154, 1155, 1156, 1161, 1163, 1165, 1166, 1168, 1169, 1174, 1180, 1181, 1183, 1184, 1188, 1190, 1191, 1193, 1194, 1195, 1196, 1197, 1202, 1204, 1206, 1209, 1211, 1212, 1213, 1214, 1216, 1217, 1220, 1222, 1223, 1226, 1230, 1233, 1241, 1247, 1248, 1249, 1250, 1252, 1256, 1257, 1259, 1260, 1261, 1263, 1266, 1271, 1275, 1276, 1277, 1288, 1293, 1295, 1298, 1299, 1306, 1310, 1312, 1319, 1320, 1321, 1322, 1333, 1335, 1339, 1340, 1342, 1343, 1345, 1348, 1349, 1351, 1355, 1361, 1363, 1368, 1381, 1382, 1385, 1390, 1397, 1399, 1400, 1401, 1405, 1413, 1420, 1423, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1436, 1437, 1440, 1446, 1447, 1450, 1452, 1453, 1455, 1456, 1459, 1462, 1464, 1466, 1468, 1469, 1475, 1476, 1477, 1480, 1481, 1486, 1492, 1493, 1494, 1499, 1502, 1503, 1504, 1510, 1511, 1514, 1515, 1516, 1523, 1524, 1526, 1533, 1534, 1539, 1540, 1544, 1545, 1550, 1551, 1552, 1553, 1554, 1557, 1558, 1561, 1565, 1566, 1569, 1574, 1584, 1589, 1590, 1596, 1600, 1601, 1603, 1607, 1608, 1609, 1610, 1611, 1612, 1614, 1627, 1628, 1629, 1631, 1633, 1634, 1638, 1639, 1641, 1642, 1648, 1651, 1653, 1657, 1662, 1663, 1665, 1668, 1669, 1671, 1673, 1674, 1678, 1679, 1685, 1687, 1689, 1692, 1702, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1720, 1721, 1723, 1724, 1725, 1727, 1729, 1735, 1736, 1739, 1740, 1743, 1747, 1751, 1760, 1761, 1762, 1763, 1781, 1788, 1792, 1793, 1798, 1801, 1802, 1803, 1806, 1808, 1821, 1824, 1828, 1830, 1831, 1832, 1833, 1836, 1838, 1842, 1848, 1856, 1857, 1860, 1862, 1867, 1868, 1870, 1871, 1873, 1875, 1876, 1883, 1885, 1886, 1889, 1891, 1893, 1894, 1895, 1897, 1898, 1899, 1903, 1922, 1924, 1929, 1930, 1931, 1934, 1935, 1938, 1939, 1941, 1945, 1946, 1949, 1952, 1953, 1960, 1962, 1964, 1972, 1973, 1977, 1981, 1985, 1986, 1988, 1989, 1997, 1999, 2000, 2013, 2015, 2018, 2030, 2031, 2033, 2041, 2043]

idx_test4=[516, 6, 1030, 1544, 2055, 1547, 11, 1038, 2062, 16, 1551, 1554, 1553, 1550, 2072, 537, 1049, 1564, 30, 1566, 2084, 1574, 39, 36, 1572, 38, 2090, 1069, 1573, 1583, 1078, 1079, 1591, 1593, 63, 66, 1603, 1605, 71, 80, 82, 83, 84, 85, 598, 89, 601, 602, 1119, 97, 1633, 1122, 609, 1638, 1132, 1648, 1655, 632, 1144, 122, 1661, 1152, 1665, 1155, 644, 1156, 1159, 1160, 652, 1166, 655, 147, 660, 1173, 1687, 664, 1689, 667, 156, 1691, 1694, 157, 672, 1696, 671, 167, 1191, 1706, 1196, 688, 181, 1206, 1232, 209, 1744, 1749, 1751, 1752, 220, 223, 1250, 740, 1767, 1769, 245, 1271, 759, 1288, 1800, 778, 1298, 1813, 1302, 1306, 794, 1311, 1829, 1840, 817, 1843, 1333, 1335, 826, 314, 317, 318, 831, 1348, 1355, 1877, 1368, 1882, 858, 860, 862, 1894, 1390, 1904, 1392, 1394, 1908, 885, 1911, 893, 898, 904, 1416, 905, 1428, 1945, 1439, 1952, 1954, 1449, 938, 941, 1453, 1454, 1971, 949, 953, 1982, 447, 960, 1985, 451, 452, 1481, 988, 477, 1508, 1001, 2028, 1517, 1010, 1021, 1535]

idx_test5=[512, 2049, 2, 5, 1542, 1543, 519, 524, 2062, 16, 1552, 534, 2071, 536, 28, 1052, 1057, 553, 2089, 1068, 558, 2094, 1584, 1074, 1231, 52, 567, 569, 2107, 1084, 586, 590, 1614, 593, 83, 1110, 1629, 97, 1634, 100, 1645, 1137, 1652, 628, 1654, 631, 1145, 1151, 1153, 1668, 650, 1677, 144, 1174, 155, 1180, 1184, 674, 1701, 1190, 683, 1196, 1197, 171, 1195, 1707, 1201, 1202, 1716, 181, 1726, 702, 1217, 196, 1733, 1226, 716, 204, 1743, 208, 209, 210, 1747, 211, 1237, 726, 724, 729, 1754, 1242, 735, 1760, 1761, 736, 737, 1252, 738, 1766, 231, 1767, 1260, 236, 239, 1777, 754, 1267, 248, 1273, 1786, 763, 1276, 1277, 1788, 255, 257, 1275, 259, 764, 1797, 1801, 779, 1806, 1295, 1807, 1299, 1818, 1310, 1824, 1827, 292, 804, 294, 1321, 1322, 1830, 1838, 1327, 813, 305, 1330, 1331, 1843, 1852, 828, 325, 1862, 841, 1353, 1867, 332, 847, 1875, 1876, 1365, 1366, 1370, 347, 348, 350, 351, 866, 1891, 356, 873, 875, 877, 1899, 367, 1903, 880, 882, 1395, 1396, 369, 376, 889, 1912, 380, 382, 898, 1930, 397, 401, 402, 1428, 404, 1429, 1430, 920, 412, 414, 930, 1452, 429, 430, 432, 434, 1972, 436, 948, 951, 1466, 445, 446, 1471, 1981, 450, 1988, 1477, 455, 456, 1993, 970, 458, 460, 1490, 2007, 471, 2011, 990, 1503, 2015, 479, 482, 1510, 1511, 493, 1007, 1523, 1529, 1018, 507]

idx_test6=[1538, 1027, 516, 5, 6, 2055, 521, 1548, 1036, 2062, 1038, 2065, 1554, 19, 2068, 21, 1551, 1048, 537, 1049, 28, 1564, 30, 2078, 36, 2084, 1574, 1572, 40, 1577, 38, 1069, 1070, 1582, 2096, 1585, 50, 1587, 1073, 52, 54, 55, 1591, 2105, 1079, 2102, 1597, 61, 63, 1088, 1084, 1603, 71, 75, 1612, 1611, 78, 80, 82, 83, 84, 85, 601, 602, 92, 90, 1119, 97, 1122, 98, 1636, 102, 104, 105, 617, 623, 1648, 115, 1655, 1144, 1657, 1658, 1152, 1665, 130, 1155, 1156, 1553, 1159, 1160, 1671, 652, 654, 655, 1167, 657, 147, 1171, 660, 662, 1173, 664, 1687, 666, 667, 156, 157, 1694, 1181, 1697, 1183, 1180, 678, 1191, 167, 1194, 1706, 684, 685, 688, 176, 178, 1714, 692, 1204, 1206, 1718, 708, 710, 1734, 720, 1744, 211, 213, 1749, 1751, 1243, 225, 1250, 228, 1253, 230, 1767, 1255, 1770, 1777, 754, 1268, 245, 759, 1277, 1791, 257, 1283, 1287, 1288, 266, 1803, 1580, 1298, 1299, 787, 1302, 278, 1816, 1311, 1829, 293, 1834, 1839, 817, 1843, 1333, 1335, 1339, 829, 318, 831, 1348, 1355, 850, 1362, 1368, 1882, 862, 863, 1376, 1894, 362, 1901, 1390, 879, 1392, 1904, 369, 1908, 1397, 885, 904, 1417, 1930, 1425, 1432, 1433, 1437, 1439, 1952, 931, 938, 1451, 941, 1453, 1454, 1971, 949, 1974, 953, 1467, 1980, 447, 1471, 962, 451, 452, 1986, 1481, 1993, 1485, 2001, 2005, 1497, 2010, 987, 988, 1508, 1001, 2028, 2029, 2030, 1517, 1009, 498, 1013, 2042, 1021, 1535]

idx_test7=[1538, 1027, 516, 6, 521, 1548, 19, 21, 537, 1564, 30, 36, 1572, 1577, 38, 1070, 1582, 1585, 50, 1587, 1073, 52, 54, 1591, 1079, 2102, 1597, 61, 1088, 75, 601, 602, 92, 90, 1119, 97, 1122, 1636, 105, 617, 623, 115, 1655, 1144, 1658, 1152, 130, 1159, 1160, 654, 655, 1167, 657, 147, 1171, 662, 1173, 666, 156, 1694, 1697, 678, 167, 1706, 688, 1714, 1718, 708, 1734, 720, 1744, 211, 1749, 1253, 230, 1767, 1255, 1770, 1777, 1268, 245, 1791, 257, 1283, 1287, 1580, 787, 1302, 1816, 1311, 1829, 293, 1834, 1839, 1843, 829, 318, 831, 1362, 1882, 1376, 1901, 1392, 1904, 1908, 885, 1417, 1432, 1433, 1439, 931, 938, 1451, 941, 1454, 1971, 1974, 953, 1467, 1980, 1471, 451, 452, 1993, 1485, 2001, 2005, 1497, 2010, 988, 1508, 1001, 2028, 2029, 1517, 1009, 498, 1013, 2042, 1535]
#print("adj.shape[0]",adj.shape[0])
#idx_test8=[516, 6, 1030, 1547, 11, 537, 1564, 30, 39, 36, 1572, 38, 2090, 1573, 1583, 1078, 1079, 1591, 1593, 66, 1605, 89, 601, 602, 1119, 97, 1122, 609, 1655, 632, 1144, 122, 1661, 1152, 644, 1159, 1160, 655, 147, 1173, 156, 1691, 1694, 672, 1696, 671, 167, 1706, 688, 1232, 1744, 1749, 1752, 220, 223, 740, 1767, 1769, 245, 1800, 1813, 1302, 1311, 1829, 1840, 1843, 826, 317, 318, 831, 1877, 1882, 860, 1904, 1392, 1394, 1908, 885, 1911, 1416, 905, 1439, 1954, 1449, 938, 941, 1454, 1971, 953, 1982, 960, 451, 452, 988, 477, 1508, 1001, 2028, 1517, 1010, 1535]
idx_test8=[2, 514, 1540, 517, 2054, 519, 1539, 522, 524, 1037, 527, 528, 2063, 531, 2067, 1046, 1569, 2082, 2088, 2094, 558, 1074, 564, 567, 1609, 1610, 588, 590, 1110, 95, 1632, 1634, 1130, 1137, 628, 117, 1145, 1146, 633, 1668, 650, 144, 151, 155, 158, 1184, 165, 683, 1716, 1717, 702, 1727, 1733, 1221, 199, 1736, 1226, 723, 1748, 725, 729, 1242, 731, 1246, 735, 1760, 1761, 737, 1754, 1252, 231, 1768, 743, 236, 241, 1266, 1267, 242, 1781, 249, 251, 1276, 1788, 774, 1801, 1806, 274, 277, 1818, 797, 1824, 1826, 292, 1319, 1832, 1831, 804, 1833, 814, 305, 307, 309, 1852, 828, 1862, 1351, 841, 332, 1363, 1875, 1876, 1370, 350, 1891, 355, 873, 877, 880, 376, 889, 378, 380, 1917, 902, 1928, 1931, 907, 1421, 913, 1429, 1430, 919, 407, 410, 414, 1446, 1960, 937, 1452, 1965, 1966, 1972, 951, 441, 442, 1979, 444, 1469, 1468, 445, 450, 1988, 1989, 454, 455, 1992, 1480, 458, 970, 1487, 464, 1999, 981, 2006, 2007, 1495, 2011, 989, 2018, 1506, 995, 997, 1505, 1000, 1515, 1516, 493, 1007, 496, 1523, 2037, 1528, 1017, 1018, 2044]

idx_test=np.array(idx_test8)

#idx_test=idx_test1

idx_unlabeled = np.union1d(idx_val, idx_test)





perturbations = int(args.ptb_rate * (adj.sum()//2))

adj, features, labels = preprocess(adj, features, labels, preprocess_adj=False)



# set up attack model
if 'Self' in args.model:
    lambda_ = 0
if 'Train' in args.model:
    lambda_ = 1
if 'Both' in args.model:
    lambda_ = 0.5

if 'A' in args.model:
    model = MetaApprox(nfeat=features.shape[1], hidden_sizes=[args.hidden],
                       nnodes=adj.shape[0], nclass=nclass, dropout=0.5,
                       train_iters=100, attack_features=False, lambda_=lambda_, device=device)

else:
    model = Metattack(nfeat=features.shape[1], hidden_sizes=[args.hidden],
                       nnodes=adj.shape[0], nclass=nclass, dropout=0.5,
                       train_iters=100, attack_features=False, lambda_=lambda_, device=device)

if device != 'cpu':
    adj = adj.to(device)
    features = features.to(device)
    labels = labels.to(device)
    model = model.to(device)


def test(adj):
    ''' test on HITSGNN '''

    adj = normalize_adj_tensor(adj)
    hitsgnn = HITSGNN(nfeat=features.shape[1],
              nhid=args.hidden,
              nclass=labels.max().item() + 1,
              dropout=0.5)

    if device != 'cpu':
        hitsgnn = hitsgnn.to(device)

    optimizer = optim.Adam(hitsgnn.parameters(),
                           lr=args.lr, weight_decay=5e-4)

    hitsgnn.train()

    for epoch in range(args.epochs):
        optimizer.zero_grad()
        output = hitsgnn(features, adj)
        loss_train = F.nll_loss(output[idx_train], labels[idx_train])
        acc_train = accuracy(output[idx_train], labels[idx_train])
        loss_train.backward()
        optimizer.step()

    hitsgnn.eval()
    output = hitsgnn(features, adj)


    loss_test = F.nll_loss(output[idx_test], labels[idx_test])
    acc_test = accuracy(output[idx_test], labels[idx_test])


    # print("Test set results:",
    #       "loss= {:.4f}".format(loss_test.item()),
    #       "accuracy= {:.4f}".format(acc_test.item()))

    return acc_test.item()


def main():

    acc = []
    runs = 1
    
    for i in range(runs):
        acc.append(test(adj))

    torch.cuda.empty_cache()

    #for i in range(3):
    
    modified_adj = model(features, adj, labels, idx_train,
                            idx_unlabeled, perturbations, ll_constraint=False)
    modified_adj = modified_adj.detach()

    for i in range(runs):
        acc.append(test(modified_adj))

    print("acc",acc)



    #data=pd.DataFrame({"Acc. Clean":clean_acc,"Acc. Perturbed":attacked_acc})

    #plt.figure(figsize=(6,6))
    #sns.boxplot(data=data)#, re_trainings*[accuracy_logistic]])

    #plt.title("Accuracy before/after perturbing {}% edges using model {}".format(args.ptb_rate*100, args.model))
    #plt.savefig("results_on_{}.png".format(args.dataset), dpi=600)
    #plt.show()


if __name__ == '__main__':
    main()

#neighbor type 0:
#acc [0.686611374407583, 0.5912322274881517, 0.5136255924170616, 0.4614928909952607]
#acc [0.686611374407583, 0.5930094786729858, 0.5829383886255924, 0.5734597156398105]

#neighbor type 1:
#acc [0.8177339901477833, 0.6945812807881774,  0.6650246305418719, 0.6847290640394089]
#acc [0.8177339901477833, 0.6009852216748769, 0.5714285714285714, 0.5960591133004927]

#neighbor type 2:
#acc [0.7228260869565217, 0.671195652173913, 0.671195652173913, 0.6929347826086957]
#acc [0.7228260869565217, 0.720108695652174, 0.6983695652173912, 0.7065217391304348]

#neighbor type 3:
#[0.7816091954022988, 0.6508620689655172, 0.5574712643678161, 0.5933908045977011]
#acc [0.7816091954022988, 0.6609195402298851, 0.5387931034482758, 0.4425287356321839]
    
#neighbor type 4:
#[0.7344632768361582, 0.6610169491525424,  0.6497175141242938, 0.6440677966101694]
#acc [0.7344632768361582, 0.6836158192090396, 0.6384180790960452, 0.6440677966101694]

#neighbor type 5:
#[0.7974137931034483, 0.6939655172413793, 0.6939655172413793,  0.7025862068965517]
#acc [0.7974137931034483, 0.6982758620689655, 0.6336206896551724, 0.5775862068965517]

#neighbor type 6:
#acc [0.7601626016260163, 0.7439024390243903, 0.7357723577235773, 0.7560975609756099]
#acc [0.7601626016260163, 0.7479674796747968, 0.7276422764227644, 0.7398373983739838]

#neighbor type 7:
#acc [0.6714285714285714, 0.7, 0.6571428571428571, 0.6785714285714286]

#neighbor type 8:
#acc [0.6633663366336634, 0.6039603960396039, 0.5841584158415841, 0.5841584158415841]

#neighbor type 8-0:
#acc [0.8, 0.6702702702702703, 0.6486486486486487, 0.6702702702702703]
#acc [0.8, 0.5783783783783785, 0.5837837837837838, 0.5837837837837838]

